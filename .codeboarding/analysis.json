{
  "description": "The CodeBoarding project is an AI-driven code analysis and documentation system. The Application Orchestrator manages the overall workflow, initiating static code analysis, generating prompts, and coordinating AI interpretation. The Static Analysis Engine provides code insights, which the AI Interpretation Layer processes using External LLM Services. The Prompt Management Layer optimizes LLM interactions, and the Output Generation Engine creates documentation and diagrams from the processed insights. This modular design ensures efficient processing and flexible integration with various AI models.",
  "components": [
    {
      "name": "Application Orchestrator",
      "description": "The central control unit managing the entire workflow, from initiating analysis to integrating results and coordinating output generation.",
      "referenced_source_code": [
        {
          "qualified_name": "agents.planner_agent",
          "reference_file": "agents/planner_agent.py",
          "reference_start_line": null,
          "reference_end_line": null
        },
        {
          "qualified_name": "agents.agent",
          "reference_file": "agents/agent.py",
          "reference_start_line": null,
          "reference_end_line": null
        }
      ],
      "assigned_files": [
        "main.py",
        "local_app.py",
        "github_action.py",
        "agents/planner_agent.py",
        "agents/agent.py"
      ],
      "can_expand": true
    },
    {
      "name": "Static Analysis Engine",
      "description": "Performs in-depth static code analysis across multiple languages, extracting structural and semantic information.",
      "referenced_source_code": [
        {
          "qualified_name": "static_analyzer.scanner",
          "reference_file": "static_analyzer/scanner.py",
          "reference_start_line": null,
          "reference_end_line": null
        },
        {
          "qualified_name": "static_analyzer.lsp_client.client",
          "reference_file": "static_analyzer/lsp_client/client.py",
          "reference_start_line": null,
          "reference_end_line": null
        }
      ],
      "assigned_files": [
        "static_analyzer/programming_language.py",
        "static_analyzer/reference_resolve_mixin.py",
        "static_analyzer/graph.py",
        "static_analyzer/analysis_result.py",
        "static_analyzer/scanner.py",
        "static_analyzer/typescript_config_scanner.py",
        "static_analyzer/lsp_client/typescript_client.py",
        "static_analyzer/lsp_client/client.py"
      ],
      "can_expand": true
    },
    {
      "name": "Prompt Management Layer",
      "description": "Dynamically creates, selects, and contextualizes prompts for various LLMs based on the analysis phase.",
      "referenced_source_code": [
        {
          "qualified_name": "agents.prompts.prompt_factory",
          "reference_file": "agents/prompts/prompt_factory.py",
          "reference_start_line": null,
          "reference_end_line": null
        },
        {
          "qualified_name": "agents.prompts.abstract_prompt_factory",
          "reference_file": "agents/prompts/abstract_prompt_factory.py",
          "reference_start_line": null,
          "reference_end_line": null
        },
        {
          "qualified_name": "agents.prompts.claude_prompts_bidirectional",
          "reference_file": "agents/prompts/claude_prompts_bidirectional.py",
          "reference_start_line": null,
          "reference_end_line": null
        }
      ],
      "assigned_files": [
        "agents/prompts/claude_prompts_bidirectional.py",
        "agents/prompts/gpt_prompts_unidirectional.py",
        "agents/prompts/gemini_flash_prompts_bidirectional.py",
        "agents/prompts/abstract_prompt_factory.py",
        "agents/prompts/gpt_prompts_bidirectional.py",
        "agents/prompts/prompt_factory.py",
        "agents/prompts/gemini_flash_prompts_unidirectional.py",
        "agents/prompts/claude_prompts_unidirectional.py"
      ],
      "can_expand": true
    },
    {
      "name": "AI Interpretation Layer",
      "description": "Interprets static analysis results using LLMs, processing responses to extract insights, classifications, and explanations.",
      "referenced_source_code": [
        {
          "qualified_name": "agents.abstraction_agent",
          "reference_file": "agents/abstraction_agent.py",
          "reference_start_line": null,
          "reference_end_line": null
        },
        {
          "qualified_name": "agents.details_agent",
          "reference_file": "agents/details_agent.py",
          "reference_start_line": null,
          "reference_end_line": null
        },
        {
          "qualified_name": "agents.meta_agent",
          "reference_file": "agents/meta_agent.py",
          "reference_start_line": null,
          "reference_end_line": null
        },
        {
          "qualified_name": "agents.validator_agent",
          "reference_file": "agents/validator_agent.py",
          "reference_start_line": null,
          "reference_end_line": null
        }
      ],
      "assigned_files": [
        "agents/diff_analyzer.py",
        "agents/details_agent.py",
        "agents/validator_agent.py",
        "agents/abstraction_agent.py",
        "agents/meta_agent.py",
        "agents/agent_responses.py",
        "agents/tools/read_source.py",
        "agents/tools/read_file_structure.py",
        "agents/tools/external_deps.py",
        "agents/tools/read_packages.py",
        "agents/tools/read_cfg.py",
        "agents/tools/get_method_invocations.py",
        "agents/tools/read_git_diff.py",
        "agents/tools/read_file.py",
        "agents/tools/read_structure.py",
        "agents/tools/read_docs.py"
      ],
      "can_expand": true
    },
    {
      "name": "Output Generation Engine",
      "description": "Transforms interpreted analysis results into human-readable documentation and visual diagrams.",
      "referenced_source_code": [
        {
          "qualified_name": "output_generators.markdown",
          "reference_file": "output_generators/markdown.py",
          "reference_start_line": null,
          "reference_end_line": null
        },
        {
          "qualified_name": "output_generators.html",
          "reference_file": "output_generators/html.py",
          "reference_start_line": null,
          "reference_end_line": null
        },
        {
          "qualified_name": "diagram_analysis.diagram_generator",
          "reference_file": "diagram_analysis/diagram_generator.py",
          "reference_start_line": null,
          "reference_end_line": null
        }
      ],
      "assigned_files": [
        "output_generators/sphinx.py",
        "output_generators/mdx.py",
        "output_generators/html.py",
        "output_generators/html_template.py",
        "output_generators/markdown.py",
        "diagram_analysis/analysis_json.py",
        "diagram_analysis/diagram_generator.py"
      ],
      "can_expand": true
    },
    {
      "name": "External LLM Services",
      "description": "Represents the various third-party Large Language Model services (e.g., OpenAI, Anthropic, Google Gemini) integrated with the system.",
      "referenced_source_code": [
        {
          "qualified_name": "ExternalLLMServiceAPI",
          "reference_file": "ExternalLLMServiceAPI",
          "reference_start_line": null,
          "reference_end_line": null
        }
      ],
      "assigned_files": [
        ""
      ],
      "can_expand": true
    },
    {
      "name": "Unclassified",
      "description": "Component for all unclassified files and utility functions (Utility functions/External Libraries/Dependencies)",
      "referenced_source_code": [],
      "assigned_files": [
        "vscode_constants.py",
        "utils.py",
        "setup.py",
        "duckdb_crud.py",
        "logging_config.py",
        "agents/__init__.py",
        "agents/tools/__init__.py",
        "agents/prompts/__init__.py",
        "repo_utils/__init__.py",
        "repo_utils/git_diff.py",
        "repo_utils/errors.py",
        "evals/base.py",
        "evals/cli.py",
        "evals/schemas.py",
        "evals/utils.py",
        "evals/config.py",
        "evals/definitions/static_analysis.py",
        "evals/definitions/end_to_end.py",
        "evals/definitions/scalability.py",
        "static_analyzer/__init__.py",
        "static_analyzer/lsp_client/__init__.py",
        "output_generators/__init__.py",
        "diagram_analysis/__init__.py",
        "diagram_analysis/version.py",
        "monitoring/paths.py",
        "monitoring/__init__.py",
        "monitoring/context.py",
        "monitoring/callbacks.py",
        "monitoring/stats.py",
        "monitoring/mixin.py",
        "monitoring/writers.py"
      ],
      "can_expand": false
    }
  ],
  "components_relations": [
    {
      "relation": "initiates and receives results from",
      "src_name": "Application Orchestrator",
      "dst_name": "Static Analysis Engine"
    },
    {
      "relation": "requests and receives prompts from",
      "src_name": "Application Orchestrator",
      "dst_name": "Prompt Management Layer"
    },
    {
      "relation": "sends data for interpretation to and receives insights from",
      "src_name": "Application Orchestrator",
      "dst_name": "AI Interpretation Layer"
    },
    {
      "relation": "sends requests to and receives responses from",
      "src_name": "AI Interpretation Layer",
      "dst_name": "External LLM Services"
    },
    {
      "relation": "provides final data to",
      "src_name": "Application Orchestrator",
      "dst_name": "Output Generation Engine"
    }
  ]
}
